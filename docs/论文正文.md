#论文提纲
##绪论
###课题背景
###网络爬虫现状
###意义
###本文主要贡献
###本文结构

##需求分析和解决方案
###总体需求
  本系统旨在通过网络爬虫技术，抓取拉勾网，内推网，猎聘网等当前市面上排名最靠前的几个互联网招聘网站上的IT行业招聘信息，对数据进行结构化的本地存储之后，再分类进行数据统计与分析，最后将统计结果以图表化的形式展现给求职人员。同时考虑到很多求职人员在找工作时会参考多个网站的招聘信息，劳神费力是难免的事，所以本系统也支持在线统一预览多个网站的最新招聘信息，为求职人员提供一站式的求职解决方案。
  
  本系统将重点放在招聘数据的海量爬取上。招聘数据来源拉勾网，内推网，猎聘网等流量排名最靠前的招聘网站，职位工作地点覆盖北京，上海，广州，深圳，杭州，成都，重庆，武汉等国内一二线城市，职位种类也包括了开发，运营，测试，产品经理等丰富的工种，针对每个特定的网站的每个类型的数据编写特定的爬取代码，达到尽可能全量的爬取以及无重复爬取是本系统需要重点突破的难关。

###各个子模板的需求
####多数据源的数据爬取
  为了使统计结果更具有代表性，取样范围不能仅仅局限于一两家招聘网站。然而对于不同网站的爬取策略是大不相同的，必须逐一定制。比如拉勾网的职位数据采用json格式从服务器端返回给客户端，所以只需要发送相应的请求，就能得到简洁的结构化的json数据，从中解析出感兴趣的数据是十分简单的。然而内推网的职位数据则是直接通过渲染模板的方式嵌入在结构十分复杂的Html文档中，这时候就要通过细致的观察和别出心裁的查找方式去获取想要的数据。另外爬取的性能问题也需要纳入考虑范围，因为数据量的巨大，单线程的顺序爬取会使得爬取过程耗时过长，需要借助现代计算机的多核特性去编写可以并发执行的程序。
####数据本地结构化存储
  不同的数据源抓取到的数据的结构是不一样的，但是为了后续的数据分析和展示，必须将他们转换成统一的格式。比如从拉勾网爬取到的职位信息中，薪资的格式是诸如‘3k-5k’,‘12k-18k’的格式，而内推网则是采用‘3-5k’,‘12-18k’的格式。再比如拉勾网对于工作经验的年限划分是‘经验1-3年’、‘经验3-5年’,而内推网则是‘[1-3年经验]’、‘[3-5年经验]’.还有职位的id,用以标志职位的唯一性，同一个数据源里id是不会重复的，但是不能武断的认定拉勾网的职位id一定不会和内推网中的某个职位id冲突。针对这些问题，需要设定一个统一的数据结构，不仅仅要便于数据的统计分析，还要兼容不同站点的数据特性。


####统计分析与图表化展示
 人工的去查阅每个招聘网站上的职位信息也许可以清楚的了解的各个职位的具体信息，但是难以看到整个细分行业的大体趋势，比如上海的Java开发工程师的平均薪资水平与工作年限之间的对应关系是怎样的，市场对哪个级别的工程师需求量更大等等。这些都需要对大量的真实数据做分析统计才能得出令人信服的结论，从而帮助求职人员更好的找到理想的工作。光有单调的数据虽然也可以得出想要的结论，但是如果能用丰富的图表化的形式加以展现，结论会更直观，对用户认知的冲击力也会更强，所以图表化的数据展示也是本系统的需求之一。
 
####一站式在线预览职位信息
就如同RSS(Really Simple Syndication,简易信息聚合)将想了解的资讯定期收集并整理，便于集中阅读一样。求职者在当今信息爆炸的时代，需要在多个不同的站点中来回挑选自己满意的工作，这本身是一件消耗精力和时间的事情，而且效果可能也并不理想。本系统将该问题也纳入到了需要满足的需求中。

###解决方案
首先，本系统的核心是网络爬虫技术。通俗的说，框架是完成是某种应用的半成品，提供了一些常用的工具类和一些基础通用化的组件，可以供开发人员在此基础上，更便捷的完成自己系统的开发工作。好的框架可以极大的提升程序员的开发效率。而单就Java语言来讲，成熟的爬虫框架就有非常多。为了选择合适的框架，笔者认真的了解了以下这些项目，从而完成选型工作。

- Apache Nutch : Nuctch是一个高可扩展，可伸缩的开源网络爬虫项目，由Java语言实现。Nutch作为当今最流行的开源爬虫之一，已经被企业广泛使用。而且Nutch的插件机制使得开发者可以灵活的定制网页抓取策略。另外Nutch有着悠久的发展历史，当今大名鼎鼎的Hadoop就是由Nutch发展而来。Nutch不仅仅可以在单击模式下运行，还可以以分布式的形式运行。


- Heritrix：Heritrix是一个开源的网络爬虫，用户可以用它从网上抓取想要的资源，其最出色之处在于它良好的可扩展性，方便用户实现自己的抓取逻辑。Heritrix主要有三大部件:范围部件，边界部件，处理器链。其中范围部件主要按照规则来决定将哪个URI入队列，边界部件则负责跟踪哪个预定的URI将要被收集，以及已经被收集的URI，选择下一个URI并剔除已经处理过的URI.处理器链包含若干个处理器，负责获取URI，分析结果并将它们传回给边界部件。但Heritrix也有一些局限，比如只在Linux上进行了测试，windows系统暂不支持，每个爬虫都是单独进行工作的，没有对更新做及时的修订工作等。


- Jsoup:jsoup是一款Java版的HTML解析器，可直接解析指定的URL地址，HTML文本内容。它提供了一套极为省力的API，可通过DOM,CSS以及类似于jQuery的操作方法来查询和操作数据。其最主要的特点是轻量，灵活。

结合以上的一些介绍其实可以看出，Apache Nutch和Heritrix都是功能很齐全的爬虫框架，而Jsoup其实都不算是严格意义上的爬虫框架，只是提供了类似爬虫的功能。但是最后我还是选择了Jsoup而放弃了Apache Nutch和Heritrix.因为Jsoup就已经足以满足本系统中对与爬虫技术的需求，而Apache Nutch和Heritrix属于重量级的框架，对系统的侵入性比较高，而且工作流程相对复杂，用在本系统中只能说是杀鸡用牛刀，吃力不讨好。相反Jsoup的轻量与灵活的优势在本系统的开发过程中被展现的淋漓尽致。

针对数据的本地结构化存储需求，笔者在开发的过程中设计了一个统一的BaseJobInfo实体，该实体抽象了各个目标网站上的招聘信息所共有的属性，比如工作地点，工作经验，薪资等，该实体与数据库表一对一映射，将爬取到的数据以统一个模型存储在数据库中，以供后续的统计分析操作。数据库选用的是mysql,原因也在于其开源免费而且简单易用的特性。ORM框架在Hibernate和Mybatis两者之间做出权衡之后选择了Mybatis,一方面因为Hibernate属于重量级的ORM框架，而本系统中所涉及的数据库表的数量其实是很少的，所以发挥不了Hibernate 最擅长的实体之间的one-to-many,many-to-many等关联关系的特性。另一方面现在的企业级应用中，Mybatis也越来越占上风，因为其可以进行更加细致的SQL优化，减少查询字段。

Java语言原生自带的java.lang.Math类就可以做很多数学统计操作，而针对图表化展示的需求，本系统则选用了由百度公司的技术团队维护的ECharts项目。Echarts是一个纯粹的Javascript的图标库，可以流畅的运行在PC和移动设备上，兼容当前市面上绝大部分主流浏览器（IE8/9/10/11,Chrome,Firefox,Safari等），底层依赖轻量级的Canvas类库ZRendeer,提供直观，生动，可交互迈克高度个性化定制的数据可视化图表。Echarts提供了常规的折线图，柱状图，散点图，饼图，K线图，用于统计的盒形图，用于地理数据可视化的地图，热力图等等，很好的覆盖了本系统中所涉及的展现需求。

针对于一站式在线预览职位的信息，则主要是通过AJAX发起异步请求，服务器端收到查询请求后，用过爬虫代码去抓取相应网站的职位信息，转换成站内特有的数据结构之后返回给前端页面，前端页面再通过js代码来控制数据的展现，从而满足该需求。

###本章小结
 本章的主要工作是针对系统预设的需求，进行需求评估并完成技术选型，对重要问题给出了比较详细的解决方案。


##相关技术介绍
除了上一章中提到的一些技术点，本系统还使用了其他很多技术来辅助系统的实现。

###多线程

###MVN

###github

###log4j+slf4j

###springmvc

###junit4

### Template Engine: Freemarker

### Web Container:Jetty

###Google code Style




##功能模块详细设计
###数据爬取

###结构化存储

###图表化展示

###一站式在线预览

##系统实现
老子也可以写很多，妈的。

架构描述，系统截图。


##总结及后续研究方向
###总结
###下一阶段研究方向
####公网运行
####界面美化，功能更丰富完善
####定时爬取

####增加更多数据源


##致谢
##附录


##参考文献
- 自己动手写网络爬虫
