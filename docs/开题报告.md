#开题报告


##毕业论文（设计）研究的意义

###网络爬虫的概念和分类


####概念
网络爬虫(Web Crawler)，又称为网络蜘蛛(Web Spider),是搜索引擎的基础和重要组成部分，其本质上是一段自动下载网页内容的计算机程序或自动化脚本。网络爬虫通常从一个被称为Seeds(种子集)的URL集合开始运行，首先将这些URL全部放入到一个有序的待爬取队列中，按照一定的顺序从种子集中取出URL，并下载该URL所指向的页面。对所下载的页面进行分析之后，会提取出新的URL存入到待爬取的URL队列中。如此往复循环之前的过程，直到待爬取的URL队列为空，或者满足了某个特定的条件，爬虫程序才会终止，从而完成一次遍历Web的工作。这个过程被称为网络爬行。


####网络爬虫的分类
按照实现技术和系统结构分，大致可以分为通用网络爬虫和主题网络爬虫。
####通用网络爬虫
通用搜索引擎面向的用户是不同的群体,为了满足更多大众群体的需求,它必须要做到包罗万象,因此通用爬虫的最大目标就是抓取到所有的相关页面。通用爬虫大多都是从种子页面开始,先将该页面的内容下载到本地并存储在数据库中,然后用网页链接抽取工具从刚才下载的网页中抽取链接,最后将抽取出来的链接加入到待爬取队列中。除了这些基本的操作之外,通用爬虫在爬取数据的时候,还会对其重要程度进行评估,以此来决定爬取的优先级顺序,这个重要程度的评估因素主要包括网页的质量，链接关系结构以及网页的访问情况等等。

通用网络爬虫的基本工作流程如下[23]:(1) 首先确定一部分精心挑选的种子URL;(2) 将这些URL放入到待抓取队列中;(3) 从待抓取队列中逐个取出URL,并解析出其 DNS,得到对应的主机 IP地址,再将该 URL 对应的网页内容下载到本地数据库中,最后将这些下载下来的 URL 放进已抓取队列;(4) 针对已抓取队列中的 URL 进行逐一解析,抽取其对应页面中的其他链接,最后将这些 链接地址再次放入待抓取队列中,并进入下一循环;(5) 直到满足一定的终止条件，爬虫程序结束。从上述的过程中可以看出:通用爬虫的主要目标是对整个互联网的数据进行遍历操作。其遍历的算法通常采用经典的广度优先算法或者深度优先算法。
通用网络爬虫的不足之处：(1) 搜索精度问题。自古以来，精度和广度就是两个互相制约的概念。通用爬虫的目的是尽可能搜索更多页面,所以其搜索精度必然会很低。而随着互联网信息技术的高速发展,互联网上的数据急剧增加,通用爬虫搜索到的页面也会越来越多,其搜索精度问题势必会变得越来越严重。(2) 搜索覆盖问题。尽管通用爬虫的终极目标是对整个互联网进行遍历爬取, 但是由于网络资源数量十分庞大,全球数以亿计的服务器节点中存储着无数个规模巨大的信息系统,而搜索引擎的实际覆盖率却远低于预期水平。经权威机构研究表明,即使是拥有数十亿索引规模的超级搜索引擎,其实际覆盖率也没有达到网络信息的80%。
(3) 个性化缺失问题。因为通用爬虫是随机对整个互联网的进行遍历的,其最核心的任务就是把所有含有关键字的页面都展现给用户,所以通用搜索引擎只能满足大众的基本需求,而无法满足部分用户更加精准化、个性化的需求。
(4) 效率问题。通用爬虫的工作是遍历整个数据量庞大的互联网，,其搜索效率自然不会很高。尽管硬件的性能提升可以有所弥补,但也只能算杯水车薪。对于通用爬虫的面临的种种问题[26],主题爬虫都有比较好的解决方案。它是建立在通用爬虫的基础上，经过细化而产生的一种新型爬虫技术。其不仅可以高速爬取特定信息,还能够较好的满足部分用户更加精准化和个性化的需求。而且正因为它所关注的页面较少，效率相比通用爬虫会高出很多。

####主题网络爬虫
主题网络爬虫在爬取互联网上的信息时,并不是和通用网络爬虫一样面向整个Web,而是面向确定的领域和主题,过滤掉了大量与主题无关的信息,从而使爬虫爬取到的资源只跟确定主题有关,只对跟主题有关的信息进行处理,并创建用户接口,为特定的用户构建特定主题的搜索引擎[28]。主题网络爬虫并不追求覆盖率,而是把抓取特定主题信息作为抓取目标。只服务为对该主题感兴趣的用户。主题网络爬虫采用特定的搜索策略去爬取特定信息,之后循环重复上述过程，直到满足了某个终止条件时才停止抓取。

与通用网络爬虫相比,主题网络爬虫的工作流程显得更加复杂,它需要使用网页分析算法过滤掉与主题无关的链接,而只留下和主题相关的链接,再将其放入待爬取的URL队列中。接着再用某种搜索策略从待爬取队列中选出下一个要抓取的网页 URL,这样循环重复上述过程,直到满足系统的停止 条件才停止爬取操作。与传统的网络爬虫相比,主题爬虫需要额外面对以下两个关键性问题[30]:(1) 分析和过滤网页数据(即判断网页内容跟主题是否相关);(2) 网页搜索策略(即决定待爬行URL的访问顺序)

对比二者会发现，通用网络爬虫的一般工作过程是:首先从种子URL开始,将该页面的内容抓取 并存储到本地数据库中,接着逐一对每个URL进行分析,最后将分析过的URL加入到待抓取队列中。此外,其遍历的算法通常采用经典的广度优先算法或者深度优先算法。
,而这些算法都是控制爬虫用随机抓取的方式遍历整个互联网的。
而主题网络爬虫是面向某个确定的主题工作的,爬取过程中需过滤掉与主题无关的页面URL,保证抓取到的数据与主题的相关性,然后再分析处理爬取到的数据。主题爬虫需要解决的问题是在爬取网页之前就要评估出该网页与主题的相关程度,其算法主要是基于网页拓扑结构和网页内容的分析两大类。
综上所述,对比通用爬虫，主题爬虫更“专”、“快”、“深”。“专”指的是在抓取信息时更有目的性和针对性;“快”指的是抓取效率更高,用户搜索时响应更加迅捷;“深”则指的是主题爬虫从种子URL开始抓取之后,其入链程度会更深[31]。

###互联网招聘网站现状与不足
随着互联网+时代的到来，互联网行业越来越多的的受到人们的关注，各种互联网公司如雨后春笋般成立。在给用户们开发出丰富多彩的互联网产品的同时，也提供了大量的就业机会，也催生出了一些新兴的互联网招聘网站。有别于如58同城和赶集网这些招聘需求大而全的传统招聘网站，以拉勾网和内推网为代表的新兴招聘网站把目光锁定在了互联网从业人员身上，仅提供与互联网职位相关的岗位信息，如程序员，设计师，测试，运营等岗位。

####拉勾网
拉勾网于2013年7月20日上线。截止2014年7月1日已有超过20000家互联网公司入驻，这其中既包括BAT(百度，阿里巴巴，腾讯)，优酷，乐视网，新浪等成熟稳重的大企业，也有像去哪儿，锤子科技，豌豆荚，小米等高速成长的行业新星。企业覆盖领域包括互联网，移动互联网，游戏，电子商务，大数据，社交网络，互联网金融，O2O，在线教育等25个互联网细分市场。

拉勾网如今依然发展成为国内互联网招聘的“一哥”，其产品特色是速度快，服务好，职位多。
速度快体现在拉勾网最快的求职记录是“1分种”。即求职者从发出简历到和所求职公司的HR敲定面试协议，仅仅花了一分钟。追求快是为了尽可能的缩短求职者的跳槽窗口期。
服务好体现在拉勾网功能丰富，包括对简历投递状态实时反馈，尊重求职者个人数据的私密性，提供定期职位订阅功能等等。
职位多：拉勾网是互联网行业里优质职位信息的首发平台（如腾讯微信部门的招聘信息、百度市场部创意人才招聘信息等都是第一时间通过拉勾网来发布）。

####内推网 
内推网是一个定位于互联网行业的内推，直招类型的垂直招聘平台。网站目前有两大部分功能：为积极进取的互联网人提供更好的职业发展机会；为互联网企业搜寻、招募到最合适、最优秀的人才。内推网绕过猎头，把应聘者和招聘方零距离对接起来，让招聘高效、对等、更有感情。内推网制定了一系列的规则，使企业发布的岗位信息更有效，人才的简历投递更精准，有助于降低企业招聘成本，同时提升人才被约见的次数。内推人/招聘者必须绑定公司邮箱，猎头、非互联网公司的邮箱后缀直接进入黑名单，每天只能发布2个职位信息，应聘者每天投递简历次数为0~3。


####不足之处
除了上面介绍到的拉勾网和内推网，还有像猎聘网等优秀的互联网招聘网站。这些招聘网站的产品都很优秀而且各有特色，但是从一个求职者角度考虑，求职过程中还有这样两个问题暂时没有得到解决。

1.各用人单位也会根据自己的喜好选择一到两家招聘网站来招揽人才，很少有公司会在所有的渠道上都发布招聘信息。为了不错过最佳的就业选择，有时候求职者会需要浏览多家网站的招聘信息，因为各家网站的产品风格不尽相同，这个过程中就会产生有一定的适应成本。

2.虽然招聘信息已经做到了结构化，但是当求职者在快速预览不同网站上的近百个职位信息时，也许可以对单个职位做到较为准确的判断，但是无法对整体的趋势或者说平均水平有一个比较好的认知。也就是说，缺少一个对招聘信息的多维度统计功能。

####课题研究目标

针对以上问题，笔者希望设计并开发出一个系统，利用网络爬虫技术，抓取拉勾网，内推网，猎聘网等当前市面上排名最靠前的几个互联网招聘网站上的IT行业招聘信息，对数据进行结构化的本地存储之后，再分类进行数据统计与分析，最后将统计结果以图表化的形式展现给求职人员。同时考虑到很多求职人员在找工作时会参考多个网站的招聘信息，劳神费力是难免的事，所以本系统也支持在线统一预览多个网站的最新招聘信息，为求职人员提供一站式的求职解决方案。

##毕业论文（设计）的提纲
引自正文